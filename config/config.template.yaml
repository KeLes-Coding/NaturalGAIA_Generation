# LLM API Configuration

# Default provider configuration
default_provider: "deepseek"  # 可选: openai, deepseek, gemini, custom

# 全局代理设置 (支持 http/https/socks5)
proxy: "http://127.0.0.1:7890"  # <--- 新增这里

providers:
  openai:
    api_key: ""         # 建议从环境变量读取
    base_url: "https://api.openai.com/v1"
    model: "gpt-4-turbo"
    concurrency: 5
    
  deepseek:
    api_key: "" 
    base_url: "https://api.deepseek.com" # 第三方通常兼容 OpenAI SDK
    model: "deepseek-chat"
    concurrency: 10          # 第三方通常并发限制较宽松

  custom_proxy:
    api_key: "."
    base_url: "https://your-proxy-domain.com/v1"
    model: "claude-3-5-sonnet" # 即使是 Claude，很多 Proxy 也提供 OpenAI 格式接口
    concurrency: 8

# System Prompt Settings
prompt_settings:
  temperature: 0.7
  max_tokens: 200